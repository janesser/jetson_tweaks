{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with YoloV4 and TensorRT\n",
    "\n",
    "CSI Camera is hw-acc encoding jpg frames\n",
    "\n",
    "YoloV4 imported from ONNX.\n",
    "\n",
    "TensorRT conversion is cached.\n",
    "FP32 is cast to FP16 here.\n",
    "\n",
    "TODO activate observer for object_detection\n",
    "\n",
    "## Pipeline\n",
    "- nvargus\n",
    "- GStreamer \n",
    "`nvarguscamerasrc sensor-id=%d ! video/x-raw(memory:NVMM), width=%d, height=%d, format=(string)NV12, framerate=(fraction)%d/1 ! nvvidconv flip-method=0 !  nvjpegenc`\n",
    "- manual / observer\n",
    "- preprocessor\n",
    "    - scaling and padding\n",
    "    (camera size matches)\n",
    "- TensorRT yoloV4\n",
    "- postprocessor\n",
    "    - threshold\n",
    "    - intersection over union\n",
    "    - nms\n",
    "- jupyter image widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages\n",
      "Collecting git+https://github.com/NVIDIA-AI-IOT/jetcam\n",
      "  Cloning https://github.com/NVIDIA-AI-IOT/jetcam to /tmp/pip-g27uuvee-build\n",
      "  Requirement already satisfied (use --upgrade to upgrade): jetcam==0.0.0 from git+https://github.com/NVIDIA-AI-IOT/jetcam in /usr/local/lib/python3.6/dist-packages/jetcam-0.0.0-py3.6.egg\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wget\n",
    "!pip3 install git+https://github.com/NVIDIA-AI-IOT/jetcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/yolov4.onnx'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/yolov4.anchors'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../data/coco.names'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from common import download_file\n",
    "\n",
    "YOLOv4_FILE = '../data/yolov4.onnx'\n",
    "YOLOv4_URL = 'https://media.githubusercontent.com/media/onnx/models/master/vision/object_detection_segmentation/yolov4/model/yolov4.onnx'\n",
    "\n",
    "YOLOv4_ANCHORS_FILE = '../data/yolov4.anchors'\n",
    "YOLOv4_ANCHORS_URL = 'https://raw.githubusercontent.com/onnx/models/master/vision/object_detection_segmentation/yolov4/dependencies/yolov4_anchors.txt'\n",
    "\n",
    "COCO_NAMES_FILE = '../data/coco.names'\n",
    "COCO_NAMES_URL = 'https://raw.githubusercontent.com/onnx/models/master/vision/object_detection_segmentation/yolov4/dependencies/coco.names'\n",
    "\n",
    "display(\n",
    "    download_file(YOLOv4_FILE, YOLOv4_URL)\n",
    ")\n",
    "display(\n",
    "    download_file(YOLOv4_ANCHORS_FILE, YOLOv4_ANCHORS_URL)\n",
    ")\n",
    "display(\n",
    "    download_file(COCO_NAMES_FILE, COCO_NAMES_URL)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file ../data/yolov4.trt\n"
     ]
    }
   ],
   "source": [
    "ENGINE_FILE = '../data/yolov4.trt'\n",
    "\n",
    "# FIXME https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#work_dynamic_shapes\n",
    "## network.get_input(0).shape = [1, 416, 416, 3]\n",
    "YOLOv4_DIMS = (416, 416)\n",
    "\n",
    "# del engine\n",
    "try: \n",
    "    engine\n",
    "except NameError:\n",
    "    from pycuda.tools import make_default_context\n",
    "    from onnx_to_tensorrt import get_engine\n",
    "    from common import allocate_buffers\n",
    "    \n",
    "    cfx = make_default_context()\n",
    "    engine = get_engine(YOLOv4_FILE, ENGINE_FILE)\n",
    "    inputs, outputs, bindings, stream = allocate_buffers(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import PreprocessYOLO, PostprocessYOLO, ALL_CATEGORIES\n",
    "\n",
    "try: preprocessor\n",
    "except NameError:\n",
    "    preprocessor = PreprocessYOLO(YOLOv4_DIMS)\n",
    "\n",
    "def reshape_output(trt_output):\n",
    "    if len(trt_output) % (52*52) == 0:\n",
    "        return trt_output.reshape(1, 52, 52, 3, 85)\n",
    "    elif len(trt_output) % (26*26) == 0:\n",
    "        return trt_output.reshape(1, 26, 26, 3, 85)\n",
    "    elif len(trt_output) % (13*13) == 0:\n",
    "        return trt_output.reshape(1, 13, 13, 3, 85)\n",
    "    else:\n",
    "        print('unknown trt_output size {}'.format(len(trt_output)))\n",
    "        return []\n",
    "\n",
    "def infer_from_camera(widget, camera):\n",
    "    camera.running = False\n",
    "    image = camera.read_image()\n",
    "    infer_from_bytes(widget, image)\n",
    "    \n",
    "def infer_from_change(widget, change):\n",
    "    # print(\"infering for widget {} with change {}\".format(widget, change))\n",
    "    infer_from_bytes(widget, change.new)\n",
    "\n",
    "def infer_from_bytes(widget, change):\n",
    "    from common import do_inference_v2\n",
    "    from yolo4_inference import image_ppreprocess, postprocess_bbbox, postprocess_boxes, nms, draw_bbox, get_anchors\n",
    "    import numpy as np\n",
    "\n",
    "    cfx.push()\n",
    "    \n",
    "    ## size matches, jpeg encoded\n",
    "    # image_raw, image_preprocessed = preprocessor.processLoaded(change)\n",
    "    pre_img, np_img = image_ppreprocess(change, YOLOv4_DIMS)\n",
    "\n",
    "    with engine.create_execution_context() as context:\n",
    "        inputs[0].host = pre_img\n",
    "        trt_outputs = do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)            \n",
    "        # fixed by applying preprocessors shuffle https://forums.developer.nvidia.com/t/yolo-v3-output-boxes-are-nan-both-in-python-and-c/142289/2\n",
    "\n",
    "        ## print(\"Output shape:\", list(map(lambda trt_output: trt_output.shape, trt_outputs)))\n",
    "        trt_outputs_reshaped = list(map(reshape_output, [trt_outputs[2]]))\n",
    "        # print(\"Output re-shape:\", list(map(lambda trt_output: trt_output.shape, trt_outputs_reshaped)))\n",
    "\n",
    "        ANCHORS = get_anchors(YOLOv4_ANCHORS_FILE)\n",
    "        STRIDES = np.array([8, 16, 32])\n",
    "        XYSCALE = [0.1,0.1,1.] # ORIG [1.2, 1.1, 1.05]\n",
    "\n",
    "        pred_bbox = postprocess_bbbox(trt_outputs_reshaped, ANCHORS, STRIDES, XYSCALE)\n",
    "        pp_bboxes = postprocess_boxes(pred_bbox, YOLOv4_DIMS, YOLOv4_DIMS[0], score_threshold=0.2)\n",
    "        bboxes = nms(pp_bboxes, iou_threshold=0.25, method='nms')\n",
    "\n",
    "        # bboxes.append([0,0,YOLOv4_DIMS[0]//2, YOLOv4_DIMS[1]//2, 1, 56])\n",
    "        # print('draw_bbox({}, {}, classes={})'.format(image_raw, bboxes, ALL_CATEGORIES))\n",
    "\n",
    "        boxed_image = draw_bbox(np_img, bboxes, classes=ALL_CATEGORIES)\n",
    "        widget.value = cv2.imencode('.jpg', boxed_image)[1].tobytes()\n",
    "    cfx.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crw-rw---- 1 root video 81, 3 Sep  7 18:12 /dev/video1\n",
      "crw-rw---- 1 root video 81, 0 Sep  7 18:12 /dev/video0\n"
     ]
    }
   ],
   "source": [
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorrt 7.1.3.0\n",
      "cv2 4.1.1\n"
     ]
    }
   ],
   "source": [
    "import tensorrt\n",
    "print('tensorrt %s' % tensorrt.__version__)\n",
    "\n",
    "import cv2\n",
    "print('cv2 %s' % cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'object_detection_utilities' from '/nvdli-nano/jupyter_notebooks/object_detection_utilities.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "# from object_detection_utilities import MyCamera, update_image, transform_image\n",
    "\n",
    "import object_detection_utilities\n",
    "reload(object_detection_utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<object_detection_utilities.MyCamera at 0x7f50d86b70>,\n",
       " <object_detection_utilities.MyCamera at 0x7f8c060f28>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.waveshare.com/wiki/IMX219-83_Stereo_Camera\n",
    "# Resolution: 3280 Ã— 2464 (per camera)\n",
    "WIDTH = YOLOv4_DIMS[0]\n",
    "HEIGHT = YOLOv4_DIMS[1]\n",
    "FPS = 1\n",
    "\n",
    "try: cameras\n",
    "except NameError:\n",
    "    cameraLeft = object_detection_utilities.MyCamera(capture_device=0, capture_width=WIDTH, capture_height=HEIGHT, capture_fps=FPS)\n",
    "    cameraRight = object_detection_utilities.MyCamera(capture_device=1, capture_width=WIDTH, capture_height=HEIGHT, capture_fps=FPS)\n",
    "\n",
    "    cameras = [cameraLeft, cameraRight]\n",
    "    \n",
    "display(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-41cee4c8147a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcameras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0minfer_from_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-21677381c954>\u001b[0m in \u001b[0;36minfer_from_camera\u001b[0;34m(widget, camera)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0minfer_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minfer_from_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-21677381c954>\u001b[0m in \u001b[0;36minfer_from_bytes\u001b[0;34m(widget, change)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m## size matches, jpeg encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# image_raw, image_preprocessed = preprocessor.processLoaded(change)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mpre_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_ppreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYOLOv4_DIMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_execution_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nvdli-nano/jupyter_notebooks/yolo4_inference.py\u001b[0m in \u001b[0;36mimage_ppreprocess\u001b[0;34m(image_data, target_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnp_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpre_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mpre_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nvdli-nano/jupyter_notebooks/yolo4_inference.py\u001b[0m in \u001b[0;36mimage_preprocess\u001b[0;34m(image, target_size, gt_boxes)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mih\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import yolo4_inference\n",
    "reload(yolo4_inference)\n",
    "\n",
    "import ipywidgets\n",
    "from IPython.display import display, Image\n",
    "import cv2\n",
    "\n",
    "# del widgets\n",
    "try: widgets\n",
    "except NameError:\n",
    "    widgets = []\n",
    "    \n",
    "if not widgets:\n",
    "    for camera in cameras:\n",
    "        camera.running = False\n",
    "        image_data = camera.read()\n",
    "\n",
    "        image_widget = ipywidgets.Image(\n",
    "            format = 'jpeg',\n",
    "            # value = Image('https://upload.wikimedia.org/wikipedia/commons/4/4b/What_Is_URL.jpg').data\n",
    "        )\n",
    "        \n",
    "        encoding_state, encoded_image = cv2.imencode('.jpg', image_data) \n",
    "        image_widget.value = encoded_image.tobytes()\n",
    "        \n",
    "        widgets.append(image_widget)\n",
    "\n",
    "for camera, widget in zip(cameras, widgets):\n",
    "    infer_from_camera(widget, camera)\n",
    "    camera.running = False\n",
    "    display(widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import yolo4_inference\n",
    "reload(yolo4_inference)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "try: \n",
    "    cameras[0].unobserve(obs, names=['value'])\n",
    "    cameras[0].running=False\n",
    "except NameError:\n",
    "    pass\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "# del obs\n",
    "try: obs\n",
    "except NameError:\n",
    "    obs = partial(infer_from_change, widgets[0])\n",
    "\n",
    "#cameras[0].observe(obs, names=['value'])\n",
    "cameras[0].running=True\n",
    "\n",
    "print(obs)\n",
    "print(cameras[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "releaseCams = False\n",
    "\n",
    "if releaseCams:\n",
    "    for camera in cameras:\n",
    "        camera.release()\n",
    "        cameras.remove(camera)\n",
    "cv2.destroyAllWindows()        \n",
    "        \n",
    "display(cameras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
